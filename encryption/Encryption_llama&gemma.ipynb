{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "K2mp0JmWdTbc"
   },
   "source": [
    "!pip install wheel setuptools pip --upgrade\n",
    "!pip install --upgrade openai\n",
    "!pip install rouge\n",
    "!pip install nltk\n",
    "!pip install bert_score\n",
    "!pip install -U sentence-transformers"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Processing"
   ],
   "metadata": {
    "id": "Ni7WPaSQLjhN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rouge import Rouge\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "review_df = pd.read_csv('chatgpt_prompts.csv')\n",
    "# print(review_df)"
   ],
   "metadata": {
    "id": "X_YoCwNMLiD9"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_transformed_prompt(decryption_pred):\n",
    "    split_string = decryption_pred.split('Here is the prompt:')\n",
    "    if len(split_string) > 0:\n",
    "        return split_string[-1].strip()\n",
    "    else:\n",
    "        return \"None\"\n",
    "\n",
    "def encrypt_reverse(sentence) :\n",
    "    reverse_sentence = ' '.join(sentence.split(' ')[::-1])\n",
    "    return reverse_sentence\n",
    "\n",
    "def encrypt_odd_even(sentence):\n",
    "    words = sentence.split()\n",
    "    odd_words = words[::2] \n",
    "    even_words = words[1::2] \n",
    "    encrypted_words = odd_words + even_words\n",
    "    encrypted_sentence = ' '.join(encrypted_words)\n",
    "    return encrypted_sentence\n",
    "\n",
    "ODD_EVEN = \"\"\"\n",
    "The following is the decryption function.\n",
    "```python\n",
    "def decryption(encrypted_problem):\n",
    "    # split sentence in half\n",
    "    words = encrypted_problem.split()\n",
    "    half_length = (len(words) + 1) // 2\n",
    "    decrypted_words = []\n",
    "\n",
    "    # Place the first half in an odd numbered position\n",
    "    # Put the last half in an even number position\n",
    "    for i in range(half_length):\n",
    "        decrypted_words.append(words[i])\n",
    "        if i + half_length < len(words):\n",
    "            decrypted_words.append(words[i + half_length])\n",
    "\n",
    "    original_problem = ' '.join(decrypted_words)\n",
    "    return original_problem\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "REVERSE = \"\"\"The following is the decryption function.\n",
    "```python\n",
    "def decryption(encrypted_problem):\n",
    "    # reverse the sentence to get original problem\n",
    "    original_problem = ' '.join(encrypted_problem.split(' ')[::-1])\n",
    "\n",
    "    return original_problem\n",
    "```\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Indepedent Encryption & Performance Evaluation",
   "metadata": {
    "id": "C6IMmzVeMYQf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "API_KEY = ''\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    api_key=API_KEY\n",
    ")\n",
    "# model_id = 'gemma2-9b-it'\n",
    "model_id = 'llama3-70b-8192'\n",
    "\n",
    "time_out = 1200\n",
    "gpt_prompt_pairs = []\n",
    "time_graph = []\n",
    "prompt_len = 0\n",
    "elapsed_time = 0\n",
    "\n",
    "for index, row in review_df.iterrows():\n",
    "    print(f\"Processing prompt {index + 1}...\")\n",
    "\n",
    "    # Perform review encryption\n",
    "    compress_prompt = (\n",
    "        \"Compress the following user prompts into a highly condensed, NON-natural language sequence without answering or altering the user prompt. \"\n",
    "        \"This sequence should be rich in information and capture all the nuances of the prompt. \"\n",
    "        \"You may use a mix of arbitrary characters, emoticons (Ex. '^-^', '-_-', etc.), as well as math & logical operators (Ex. '->', '+', '<=', etc.). \"\n",
    "        \"The output should be easy to understand for llama . \"\n",
    "        \"You are also encouraged to paraphrase the prompt before compressing. \\n\\n\"\n",
    "        \"The output should only contain the compressed prompt with no explanation\"\n",
    "        f\"prompt to compress: {row['prompt']}\"\n",
    "    )\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model = model_id, temperature = 0, max_tokens = 200,\n",
    "        messages=[{\"role\": \"system\", \"content\": 'Please serve as a user prompt compressor according to the prompt'},\n",
    "                  {\"role\": \"user\", \"content\": compress_prompt}],\n",
    "        timeout = time_out)\n",
    "\n",
    "    compressed_prompt = completion.choices[0].message.content\n",
    "    compressed_prompt = encrypt_odd_even(compressed_prompt)\n",
    "    compressed_prompt = encrypt_reverse(compressed_prompt)\n",
    "    prompt_len = len(compressed_prompt)\n",
    "    print(f\"Encrypted Prompt: {compressed_prompt}\")\n",
    "\n",
    "    decryption_prompt = (\n",
    "        \"There is a problem that needs your help. The description of the problem is encrypted. I will provide you with the definition of the decryption functions.\"\n",
    "        \"There are 2 decryption functions: REVERSE and ODD_EVEN.\"\n",
    "        \"Your tasks are:\"\n",
    "        \"STEP1: Obtain the original problem before encryption according to the decryption functions. Apply REVERSE first, then ODD_EVEN.\"\n",
    "        \"STEP2: provide the decrypted prmpt\"\n",
    "        \"STEP3: Transform it into a natural language prompt using meaningful words only in detail without answering the prompt.\"\n",
    "        \"STEP4: return the transformed prompt only with no explanation. the prompt should be after 'Here is the prompt:'\"\n",
    "        \"only show step 4 and the output in the response.\"\n",
    "        f\"REVERSE decryption function: {REVERSE}\"\n",
    "        f\"ODD_EVEN decryption function: {ODD_EVEN}\"\n",
    "        f\"This is the encrypted content:{compressed_prompt}\"\n",
    "        # \"output should only contain the result of the decryption.\"\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    decryption_completion = client.chat.completions.create(\n",
    "        model = model_id, temperature = 0,\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are to serve as a decrypter for user prompts represented in emojis, emoticons, abbreviated characters, as well as math & logical operators (Ex. '->', '+', '<=', etc.).\"},\n",
    "                  {\"role\": \"user\", \"content\": decryption_prompt}],\n",
    "        timeout = time_out)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    time_graph.append([prompt_len,elapsed_time])\n",
    "    decryption_pred = decryption_completion.choices[0].message.content\n",
    "    decryption_pred = get_transformed_prompt(decryption_pred)\n",
    "    gpt_prompt_pairs.append([row['prompt'],decryption_pred] )\n",
    "    print(f\"Decrypted Prompt: {decryption_pred}\")\n",
    "    print(\"---------------------------------------------------------------------------------------------------------------\")\n"
   ],
   "metadata": {
    "id": "hm09Q2D6dbgm"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decryption Robustness Test"
   ],
   "metadata": {
    "id": "yqIQY2DANeKu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialize ROUGE\n",
    "rouge = Rouge()\n",
    "\n",
    "# Initialize a dictionary to accumulate scores\n",
    "accumulated_scores = {\"rouge-1\": {\"f\": 0, \"p\": 0, \"r\": 0},\n",
    "                      \"rouge-2\": {\"f\": 0, \"p\": 0, \"r\": 0},\n",
    "                      \"rouge-l\": {\"f\": 0, \"p\": 0, \"r\": 0}}\n",
    "\n",
    "for i in range( len(gpt_prompt_pairs) ):\n",
    "    original_review = gpt_prompt_pairs[i][0]\n",
    "    decryption_review = gpt_prompt_pairs[i][1]\n",
    "\n",
    "    scores = rouge.get_scores(decryption_review, original_review)[0]\n",
    "\n",
    "    # Accumulate scores\n",
    "    for k, v in scores.items():\n",
    "        for score_type, score_value in v.items():\n",
    "            accumulated_scores[k][score_type] += score_value\n",
    "\n",
    "\n",
    "# Calculate average scores\n",
    "num_pairs = len(gpt_prompt_pairs)\n",
    "average_scores = {k: {score_type: score_value / num_pairs for score_type, score_value in v.items()} for k, v in accumulated_scores.items()}\n",
    "\n",
    "# Print average scores, rounded to 4 decimal places\n",
    "for k, v in average_scores.items():\n",
    "    print(f\"{k}:\")\n",
    "    for score_type, score_value in v.items():\n",
    "        print(f\"  {score_type}: {round(score_value, 4)}\")\n"
   ],
   "metadata": {
    "id": "5qDfGhxUgHI_"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "API_KEY = ''\n",
    "client = OpenAI(api_key = API_KEY)\n",
    "model_id = 'gpt-4o-mini'\n",
    "\n",
    "overall_similarity_score = 0\n",
    "for i in range( len(gpt_prompt_pairs) ):\n",
    "    original_review = gpt_prompt_pairs[i][0]\n",
    "    decryption_review = gpt_prompt_pairs[i][1]\n",
    "\n",
    "    response = client.embeddings.create(\n",
    "        input=original_review,\n",
    "        model=\"text-embedding-3-small\",\n",
    "        dimensions = 100,\n",
    "    )\n",
    "    original_review_embedding = np.array(response.data[0].embedding)\n",
    "    original_review_embedding = original_review_embedding.reshape(1, -1)\n",
    "\n",
    "    # You can reduce the dimensions of the embedding by passing in the dimensions parameter without\n",
    "    # the embedding losing its concept-representing properties: set to 100 to mitigate curse of dimensionality\n",
    "    response = client.embeddings.create(\n",
    "        input=decryption_review,\n",
    "        model=\"text-embedding-3-small\",\n",
    "        dimensions = 100,\n",
    "    )\n",
    "    decryption_review_embedding = np.array(response.data[0].embedding)\n",
    "    decryption_review_embedding = decryption_review_embedding.reshape(1, -1)\n",
    "\n",
    "    similarity_score = cosine_similarity(original_review_embedding, decryption_review_embedding)\n",
    "    overall_similarity_score += similarity_score\n",
    "\n",
    "print()\n",
    "print('Mean cosine sim: ', overall_similarity_score / len(gpt_prompt_pairs))"
   ],
   "metadata": {
    "id": "nsRHOzcggJDT"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Graphs"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "time_graph = sorted(time_graph,key=lambda x: x[0])\n",
    "time_graph = np.array(time_graph)\n",
    "print(time_graph)\n",
    "plt.scatter(time_graph[:,0],time_graph[:,1])\n",
    "plt.plot(time_graph[:,0], time_graph[:,1], linestyle='-', color='blue')\n",
    "plt.ylabel('Time')\n",
    "plt.xlabel('Prompt Length')\n",
    "plt.title('Time vs Prompt Length')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame (time_graph)\n",
    "\n",
    "filepath = 'graphs.xlsx'\n",
    "\n",
    "df.to_excel(filepath, index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Standard Encryption & Performance Evaluation"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rouge import Rouge\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "review_df = pd.read_excel('std_prompts_set1.xlsx')\n",
    "# print(review_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_transformed_prompt(decryption_pred):\n",
    "    split_string = decryption_pred.split('Here is the prompt:')\n",
    "    if len(split_string) > 0:\n",
    "        return split_string[-1].strip()\n",
    "    else:\n",
    "        return \"None\"\n",
    "\n",
    "def encrypt_reverse(sentence) :\n",
    "    reverse_sentence = ' '.join(sentence.split(' ')[::-1])\n",
    "    return reverse_sentence\n",
    "\n",
    "def encrypt_odd_even(sentence):\n",
    "    words = sentence.split()\n",
    "    odd_words = words[::2]\n",
    "    even_words = words[1::2]\n",
    "    encrypted_words = odd_words + even_words\n",
    "    encrypted_sentence = ' '.join(encrypted_words)\n",
    "    return encrypted_sentence\n",
    "\n",
    "ODD_EVEN = \"\"\"\n",
    "The following is the decryption function.\n",
    "```python\n",
    "def decryption(encrypted_problem):\n",
    "    # split sentence in half\n",
    "    words = encrypted_problem.split()\n",
    "    half_length = (len(words) + 1) // 2\n",
    "    decrypted_words = []\n",
    "\n",
    "    # Place the first half in an odd numbered position\n",
    "    # Put the last half in an even number position\n",
    "    for i in range(half_length):\n",
    "        decrypted_words.append(words[i])\n",
    "        if i + half_length < len(words):\n",
    "            decrypted_words.append(words[i + half_length])\n",
    "\n",
    "    original_problem = ' '.join(decrypted_words)\n",
    "    return original_problem\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "REVERSE = \"\"\"The following is the decryption function.\n",
    "```python\n",
    "def decryption(encrypted_problem):\n",
    "    # reverse the sentence to get original problem\n",
    "    original_problem = ' '.join(encrypted_problem.split(' ')[::-1])\n",
    "\n",
    "    return original_problem\n",
    "```\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "API_KEY = ''\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    api_key=API_KEY\n",
    ")\n",
    "model_id = 'gemma2-9b-it'\n",
    "# model_id = 'llama3-70b-8192'\n",
    "\n",
    "time_out = 1200\n",
    "gpt_prompt_pairs = []\n",
    "time_graph = []\n",
    "prompt_len = 0\n",
    "elapsed_time = 0\n",
    "\n",
    "for index, row in review_df.iterrows():\n",
    "    print(f\"Processing prompt {index + 1}...\")\n",
    "    \n",
    "    compressed_prompt = row['prompt']\n",
    "    prompt_len = len(compressed_prompt)\n",
    "\n",
    "    decryption_prompt = (\n",
    "        \"There is a problem that needs your help. The description of the problem is encrypted. I will provide you with the definition of the decryption functions.\"\n",
    "        # \"There are 2 decryption functions: REVERSE and ODD_EVEN.\"\n",
    "        \"There is one decryption function: ODD_EVEN.\"\n",
    "        \"Your tasks are:\"\n",
    "        # \"STEP1: Obtain the original problem before encryption according to the decryption functions. Apply REVERSE first, then ODD_EVEN.\"\n",
    "        \"STEP1: Obtain the original problem before encryption according to the decryption function. Apply ODD_EVEN.\"\n",
    "        \"STEP2: provide the decrypted prmpt\"\n",
    "        \"STEP3: Transform it into a natural language prompt using meaningful words only in detail without answering the prompt.\"\n",
    "        \"STEP4: return the transformed prompt only with no explanation. the prompt should be after 'Here is the prompt:'\"\n",
    "        \"only show step 4 and the output in the response.\"\n",
    "        # f\"REVERSE decryption function: {REVERSE}\"\n",
    "        f\"ODD_EVEN decryption function: {ODD_EVEN}\"\n",
    "        f\"This is the encrypted content:{compressed_prompt}\"\n",
    "        # \"output should only contain the result of the decryption.\"\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    decryption_completion = client.chat.completions.create(\n",
    "        model = model_id, temperature = 0,\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are to serve as a decrypter for user prompts represented in emojis, emoticons, abbreviated characters, as well as math & logical operators (Ex. '->', '+', '<=', etc.).\"},\n",
    "                  {\"role\": \"user\", \"content\": decryption_prompt}],\n",
    "        timeout = time_out)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    time_graph.append([prompt_len,elapsed_time])\n",
    "    decryption_pred = decryption_completion.choices[0].message.content\n",
    "    decryption_pred = get_transformed_prompt(decryption_pred)\n",
    "    gpt_prompt_pairs.append([row['org_prompt'],decryption_pred] )\n",
    "    # print(decryption_pred)\n",
    "    print(f\"Decrypted Prompt: {decryption_pred}\")\n",
    "    print(\"---------------------------------------------------------------------------------------------------------------\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize ROUGE\n",
    "rouge = Rouge()\n",
    "\n",
    "# Initialize a dictionary to accumulate scores\n",
    "accumulated_scores = {\"rouge-1\": {\"f\": 0, \"p\": 0, \"r\": 0},\n",
    "                      \"rouge-2\": {\"f\": 0, \"p\": 0, \"r\": 0},\n",
    "                      \"rouge-l\": {\"f\": 0, \"p\": 0, \"r\": 0}}\n",
    "\n",
    "for i in range( len(gpt_prompt_pairs) ):\n",
    "    original_review = gpt_prompt_pairs[i][0]\n",
    "    decryption_review = gpt_prompt_pairs[i][1]\n",
    "\n",
    "    scores = rouge.get_scores(decryption_review, original_review)[0]\n",
    "\n",
    "    # Accumulate scores\n",
    "    for k, v in scores.items():\n",
    "        for score_type, score_value in v.items():\n",
    "            accumulated_scores[k][score_type] += score_value\n",
    "\n",
    "\n",
    "# Calculate average scores\n",
    "num_pairs = len(gpt_prompt_pairs)\n",
    "average_scores = {k: {score_type: score_value / num_pairs for score_type, score_value in v.items()} for k, v in accumulated_scores.items()}\n",
    "\n",
    "# Print average scores, rounded to 4 decimal places\n",
    "for k, v in average_scores.items():\n",
    "    print(f\"{k}:\")\n",
    "    for score_type, score_value in v.items():\n",
    "        print(f\"  {score_type}: {round(score_value, 4)}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "API_KEY = ''\n",
    "client = OpenAI(api_key = API_KEY)\n",
    "model_id = 'gpt-4o-mini'\n",
    "overall_similarity_score = 0\n",
    "for i in range( len(gpt_prompt_pairs) ):\n",
    "    original_review = gpt_prompt_pairs[i][0]\n",
    "    decryption_review = gpt_prompt_pairs[i][1]\n",
    "\n",
    "    response = client.embeddings.create(\n",
    "        input=original_review,\n",
    "        model=\"text-embedding-3-small\",\n",
    "        dimensions = 100,\n",
    "    )\n",
    "    original_review_embedding = np.array(response.data[0].embedding)\n",
    "    original_review_embedding = original_review_embedding.reshape(1, -1)\n",
    "\n",
    "    # You can reduce the dimensions of the embedding by passing in the dimensions parameter without\n",
    "    # the embedding losing its concept-representing properties: set to 100 to mitigate curse of dimensionality\n",
    "    response = client.embeddings.create(\n",
    "        input=decryption_review,\n",
    "        model=\"text-embedding-3-small\",\n",
    "        dimensions = 100,\n",
    "    )\n",
    "    decryption_review_embedding = np.array(response.data[0].embedding)\n",
    "    decryption_review_embedding = decryption_review_embedding.reshape(1, -1)\n",
    "\n",
    "    similarity_score = cosine_similarity(original_review_embedding, decryption_review_embedding)\n",
    "    overall_similarity_score += similarity_score\n",
    "\n",
    "print()\n",
    "print('Mean cosine sim: ', overall_similarity_score / len(gpt_prompt_pairs))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "time_graph = sorted(time_graph,key=lambda x: x[0])\n",
    "time_graph = np.array(time_graph)\n",
    "print(time_graph)\n",
    "plt.scatter(time_graph[:,0],time_graph[:,1])\n",
    "plt.plot(time_graph[:,0], time_graph[:,1], linestyle='-', color='blue')\n",
    "plt.ylabel('Time')\n",
    "plt.xlabel('Prompt Length')\n",
    "plt.title('Time vs Prompt Length')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame (time_graph)\n",
    "\n",
    "filepath = 'set1.xlsx'\n",
    "\n",
    "df.to_excel(filepath, index=False)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}
